{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5fde7e60-ed28-4311-a5bd-12ac408e18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c83ac16-5729-4ee9-ba8a-617d23b7183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"\n",
    "널 품기 전 알지 못했다\n",
    "내 머문 세상 이토록\n",
    "찬란한 것을\n",
    "작은 숨결로 닿은 사람\n",
    "겁 없이 나를 불러준 사랑\n",
    "몹시도 좋았다\n",
    "너를 지켜보고 설레고\n",
    "우습게 질투도 했던\n",
    "평범한 모든 순간들이\n",
    "캄캄한 영원\n",
    "그 오랜 기다림 속으로\n",
    "햇살처럼 니가 내렸다\n",
    "널 놓기 전 알지 못했다\n",
    "내 머문 세상 이토록\n",
    "쓸쓸한 것을\n",
    "고운 꽃이 피고 진 이 곳\n",
    "다시는 없을 너라는 계절\n",
    "욕심이 생겼다\n",
    "너와 함께 살고 늙어가\n",
    "주름진 손을 맞잡고\n",
    "내 삶은 따뜻했었다고\n",
    "단 한번 축복\n",
    "그 짧은 마주침이 지나\n",
    "빗물처럼 너는 울었다\n",
    "한번쯤은 행복하고\n",
    "싶었던 바람\n",
    "너까지 울게 만들었을까\n",
    "모두, 잊고 살아가라\n",
    "내가 널, 찾을 테니\n",
    "니 숨결, 다시 나를 부를 때\n",
    "잊지 않겠다\n",
    "너를 지켜보고 설레고\n",
    "우습게 질투도 했던\n",
    "니가 준 모든 순간들을\n",
    "언젠가 만날\n",
    "우리 가장 행복할 그날\n",
    "첫눈처럼 내가 가겠다\n",
    "너에게 내가 가겠다\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77e60983-80d8-4ddd-a294-703be00b56c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data):\n",
    "    tokens = data.split()\n",
    "    vocab = list(set(tokens))\n",
    "    vocab_size = len(vocab)\n",
    "\n",
    "    word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "    ix_to_word = {i: word for i, word in enumerate(vocab)}\n",
    "\n",
    "    return tokens, vocab_size, word_to_ix, ix_to_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "772fa69f-0e0c-4111-bc6f-45ba3057b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, hidden_size, input_size, learning_rate, seq_len):\n",
    "        #하이퍼 파라미터\n",
    "        self.learning_rate = learning_rate\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_len = seq_len\n",
    "        self.hprev = np.zeros((hidden_size, 1)) # hidden_state t == 0 일때 즉, 초기 히든 스테이트\n",
    "\n",
    "        self.input_size = input_size\n",
    "        # input(x) -> input_Size x 1\n",
    "        # hidden_state -> hidden_size x 1 \n",
    "        self.U = np.random.randn(hidden_size, input_size) * 0.01 # U x input(x) \n",
    "        \n",
    "        self.W = np.random.randn(hidden_size, hidden_size) * 0.01 # W x hidden_state + bw\n",
    "        self.bw = np.zeros((hidden_size, 1))\n",
    "        \n",
    "        self.V = np.random.randn(input_size, hidden_size) * 0.01 # V x hidden_state + bv\n",
    "        self.bv = np.zeros((input_size, 1))\n",
    "        \n",
    "        self.xs, self.hs, self.ps, self.ys = {}, {}, {}, {}\n",
    "\n",
    "    \n",
    "    def feedforward(self, inputs,targets):\n",
    "        loss = 0\n",
    "        self.hs[-1] = np.copy(self.hprev)\n",
    "        \n",
    "        for i in range(self.seq_len):\n",
    "            self.xs[i] = np.zeros((self.input_size, 1))\n",
    "            self.xs[i][inputs[i]] = 1  #input의 one hot encoding \n",
    "          \n",
    "            self.hs[i] = np.tanh(np.dot(self.U, self.xs[i]) + np.dot(self.W, self.hs[i - 1]) + self.bw)\n",
    "            \n",
    "            self.ys[i] = np.dot(self.V, self.hs[i]) + self.bv\n",
    "            \n",
    "            self.ps[i] = np.exp(self.ys[i]) / np.sum(np.exp(self.ys[i]))  # softmax\n",
    "          \n",
    "            loss += -np.log(self.ps[i][targets[i]][0]) # loss function으로 cross_Entropy\n",
    "        return loss\n",
    "    def backward(self, targets):\n",
    "    # Backward propagation through time (BPTT)\n",
    "    # 처음에 모든 가중치들은 0으로 설정\n",
    "        dV = np.zeros(self.V.shape)\n",
    "        dW = np.zeros(self.W.shape)\n",
    "        dU = np.zeros(self.U.shape)\n",
    "        dbv = np.zeros(self.bv.shape)\n",
    "        dbw = np.zeros(self.bw.shape)\n",
    "        for i in range(self.seq_len)[::-1]:\n",
    "            output = np.zeros((self.input_size, 1))\n",
    "            output[targets[i]] = 1\n",
    "            self.ps[i] = self.ps[i] - output.reshape(-1, 1)\n",
    "        # 매번 i스텝에서 dL/dVi를 구하기\n",
    "            dV_step_i = self.ps[i] @ (self.hs[i]).T  # (y_hat - y) @ hs.T - for each step\n",
    "            dbv = self.ps[i]\n",
    "            dV = dV + dV_step_i  # dL/dVi를 다 더하기\n",
    "\n",
    "        # 각i별로 V와 W를 구하기 위해서는\n",
    "        # 먼저 공통적으로 계산되는 부분을 delta로 해서 계산해두고\n",
    "        # 그리고 시간을 거슬러 dL/dWij와 dL/dUij를 구한 뒤\n",
    "        # 각각을 합하여 dL/dW와 dL/dU를 구하고 \n",
    "        # 다시 공통적으로 계산되는 delta를 업데이트\n",
    "\n",
    "        # i번째 스텝에서 공통적으로 사용될 delta\n",
    "            delta_recent = (self.V.T @ self.ps[i]) * (1 - self.hs[i] ** 2)\n",
    "\n",
    "        # 시간을 거슬러 올라가서 dL/dW와 dL/dU를 구하\n",
    "            for j in range(i + 1)[::-1]:\n",
    "                dbw += delta_recent\n",
    "                dW_ij = delta_recent @ self.hs[j - 1].T\n",
    "\n",
    "                dW = dW + dW_ij\n",
    "\n",
    "                dU_ij = delta_recent @ self.xs[j].reshape(1, -1)\n",
    "                dU = dU + dU_ij\n",
    "\n",
    "            # 그리고 다음번 j번째 타임에서 공통적으로 계산할 delta를 업데이트\n",
    "                delta_recent = (self.W.T @ delta_recent) * (1 - self.hs[j - 1] ** 2)\n",
    "\n",
    "            for d in [dU, dW, dV]:\n",
    "                np.clip(d, -1, 1, out=d)\n",
    "                \n",
    "        self.W -= self.learning_rate * dW\n",
    "        self.U -= self.learning_rate * dU\n",
    "        self.V -= self.learning_rate * dV\n",
    "        self.bv -= self.learning_rate * dbv\n",
    "        self.bw -= self.learning_rate * dbw\n",
    "        self.hprev = self.hs[len(inputs) - 1]\n",
    "        \n",
    "    def predict(self, word, length):\n",
    "        \n",
    "        x = np.zeros((self.input_size, 1))\n",
    "        x[word_to_ix[word]] = 1\n",
    "        ixes = []\n",
    "        h = np.zeros((self.hidden_size,1))\n",
    "\n",
    "        for t in range(length):\n",
    "            h = np.tanh(np.dot(self.U, x) + np.dot(self.W, h))\n",
    "            y = np.dot(self.V, h)\n",
    "            p = np.exp(y) / np.sum(np.exp(y))    # softmax\n",
    "            ix = np.argmax(p)                    # 가장 높은 확률의 index return\n",
    "            x = np.zeros((self.input_size, 1))        # 다음 input one hot encoding\n",
    "            x[ix] = 1\n",
    "            ixes.append(ix) \n",
    "            \n",
    "        pred_words = word + ' '+' '.join(ix_to_word[i] for i in ixes)\n",
    "        return pred_words\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b41e289b-46dd-4dea-b511-2214b459cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, vocab_size, word_to_ix, ix_to_word = data_preprocessing(data)\n",
    "seq_len=1\n",
    "h_size=100\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "rnn = RNN(h_size, vocab_size, learning_rate, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "494a9ab2-562a-4563-87e9-862ba63db01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 4.644721672329932\n",
      "epoch 100, loss: 3.835155015840123\n",
      "epoch 200, loss: 0.1022253581285526\n",
      "epoch 300, loss: 0.01991212294776481\n",
      "epoch 400, loss: 0.00975137488728447\n",
      "epoch 500, loss: 0.006250863842611008\n",
      "epoch 600, loss: 0.0045618762418998295\n",
      "epoch 700, loss: 0.003580000333975143\n",
      "epoch 800, loss: 0.002940009316026212\n",
      "epoch 900, loss: 0.002490519774959017\n"
     ]
    }
   ],
   "source": [
    "p=0\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for p in range(len(tokens)-seq_len):\n",
    "        inputs = [word_to_ix[tok] for tok in tokens[p:p + seq_len]]\n",
    "        targets = [word_to_ix[tok] for tok in tokens[p + 1:p + seq_len + 1]]\n",
    "\n",
    "        loss = rnn.feedforward(inputs,targets)\n",
    "        rnn.backward(targets)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'epoch {epoch}, loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d1e0cdc9-2782-4a1b-8dcf-164d7969aeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'널 품기 전 알지 못했다 내 머문 세상 이토록 찬란한 것을 작은 숨결로 닿은 사람 겁 없이 나를 불러준 사랑 몹시도 좋았다 너를 지켜보고 설레고 우습게 질투도 했던 평범한 모든 순간들이 캄캄한 영원 그 오랜 기다림 속으로 햇살처럼 니가 내렸다 널 놓기 전 알지 못했다 내 머문 세상 이토록 쓸쓸한 것을 고운 꽃이 피고 진 이 곳 다시는 없을 너라는 계절 욕심이 생겼다 너와 함께 살고 늙어가 주름진 손을 맞잡고 내 삶은 따뜻했었다고 단 한번 축복 그 짧은 마주침이 지나 빗물처럼 너는 울었다 한번쯤은 행복하고 싶었던 바람 너까지 울게 만들었을까 모두, 잊고 살아가라 내가 널, 찾을 테니 니 숨결, 다시 나를 부를 때 잊지 않겠다 너를 지켜보고 설레고 우습게 질투도 했던 니가 준 모든 순간들을 언젠가 만날 우리 가장 행복할 그날 첫눈처럼 내가 가겠다 너에게 내가 가겠다'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.predict(\"널\",126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d0ecf-12bd-4f9f-826c-38c3f1f07469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
